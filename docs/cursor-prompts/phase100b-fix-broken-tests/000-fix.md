# Phase 100b — Fix 121 Broken Tests + Set Realistic Coverage Threshold

## Problem

121 unit tests are failing. These are pre-existing failures from prior refactors:
- Phase 95 deleted the `integrations`, `delivery_jobs`, `integration_routes` tables and API endpoints
- Phase 96/96b deleted the integration code from customer.py
- Tests that reference deleted tables or deleted routes now fail with ImportError or AttributeError

Coverage is 20.87% against a 65% threshold — CI is red.
The threshold is wrong, not the coverage. Unit tests that mock the DB will never hit 65%.

## Step 1: Triage the 121 failures

Run the failing tests and categorize them:

```bash
cd /home/opsconductor/simcloud
pytest tests/unit/ -v --tb=line 2>&1 | grep "FAILED" | head -50
```

Then get the distinct failure reasons:
```bash
pytest tests/unit/ --tb=line 2>&1 | grep -E "^E\s+" | sort | uniq -c | sort -rn | head -20
```

Expected failure categories:
1. **ImportError: cannot import 'integrations' / 'delivery_jobs' / 'AlertPayload'** — tests importing deleted code
2. **AttributeError: router has no attribute 'integrations'** — tests referencing removed routes
3. **404 Not Found on /customer/integrations** — tests calling deleted endpoints
4. **Table 'delivery_jobs' does not exist** — tests querying dropped tables

## Step 2: Delete tests for deleted functionality

Any test file or test function that exclusively tests:
- `/customer/integrations` endpoints
- `/customer/integration-routes` endpoints
- `/customer/delivery-jobs` endpoints
- `delivery_jobs` table queries
- `integrations` table queries

**Delete them.** They test functionality that no longer exists. There is no value in keeping
a test for a deleted feature.

Search for affected test files:
```bash
rg "integrations|delivery_jobs|integration_routes|AlertPayload|dispatch_to_integration" \
  tests/unit/ --type py -l
```

For each file found:
- If the entire file tests only deleted functionality → delete the whole file
- If the file has some tests for deleted code and some for surviving code → delete only
  the functions that test deleted code, keep the rest

## Step 3: Fix tests for refactored code

Some tests may fail because code moved to a new location (e.g., routes extracted from
customer.py to devices.py, alerts.py, metrics.py, exports.py).

For these: update the import path, not the test logic.

Example:
```python
# OLD (broken after Phase 96):
from routes.customer import list_devices

# NEW (correct after Phase 96):
from routes.devices import list_devices
```

Find all import path errors:
```bash
pytest tests/unit/ --tb=short 2>&1 | grep "ImportError\|ModuleNotFoundError" | sort -u
```

Fix each import to point to the new module location.

## Step 4: Fix the coverage threshold

The 65% threshold is wrong for unit tests. Here is what the numbers actually mean:

| Test type | Coverage they produce | Why |
|-----------|----------------------|-----|
| Unit tests (mocked DB) | 15-30% | Only pure logic paths are covered; DB/network calls are mocked out |
| Integration tests (real DB) | 50-75% | Route handlers execute fully against a real DB |
| E2E tests (full stack) | 60-80% | Covers the widest surface area |

**The right threshold per test type:**

### `.coveragerc` — revert to realistic unit test threshold
```ini
[run]
source = services/ui_iot
omit = */tests/*, */__pycache__/*, */migrations/*
branch = True
fail_under = 30   # realistic for unit tests with mocked DB

[report]
show_missing = True
precision = 2
```

### `.github/workflows/test.yml` — apply different thresholds per test type
Find the integration test step and set a higher threshold there:
```yaml
# Unit tests — low threshold (mocked DB)
- name: Unit tests
  run: pytest -m unit -v --tb=short --cov=services/ui_iot --cov-fail-under=30

# Integration tests — higher threshold (real DB)
- name: Integration tests
  run: pytest -m integration -v --tb=short --cov=services/ui_iot --cov-fail-under=55
```

Remove the `--cov-fail-under=65` that was added in Phase 100 from the unit test run.

## Step 5: Verify CI is green

```bash
# Run unit tests only — should pass at 30% threshold
pytest tests/unit/ -v --tb=short \
  --cov=services/ui_iot \
  --cov-fail-under=30 2>&1 | tail -15
```

Expected:
- 0 failures (all broken tests deleted or fixed)
- Coverage >= 30%
- Exit code 0

```bash
# Quick check — confirm no import errors remain
pytest tests/unit/ --co -q 2>&1 | grep -E "ERROR|ImportError" | head -10
# Expected: no output
```

## Step 6: Commit

```bash
git add \
  tests/unit/ \
  .coveragerc \
  .github/workflows/test.yml

git commit -m "fix: remove deleted-functionality tests, fix import paths, set realistic thresholds

- Deleted unit tests for integrations/delivery_jobs/integration_routes endpoints
  (tables and routes were removed in phases 95-96b; tests have no value)
- Fixed import paths for tests affected by route extraction (phase 96)
- .coveragerc: fail_under 65 → 30 (unit tests with mocked DB realistically reach ~25-30%)
- CI: unit test threshold 30%, integration test threshold 55%
- Result: full unit suite passes cleanly"

git push origin main
git log --oneline -3
```

## Definition of Done

- [ ] `pytest tests/unit/` exits with 0 failures
- [ ] Coverage >= 30% in unit test run
- [ ] No ImportError or AttributeError in test collection
- [ ] New tests from Phase 100 (evaluator, ingest, isolation) still pass
- [ ] CI pipeline is green
